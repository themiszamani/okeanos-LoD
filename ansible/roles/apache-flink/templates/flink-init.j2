#!/bin/bash

# Source environment file to make sure HADOOP_HOME variable is available.
source /etc/environment

# Define the user that should run this script.
SCRIPT_USER=flink

# The path where Apache Flink is installed.
INSTALLATION_PATH="{{ installation_path }}"

# The full path of the pid file to use. Apache Flink is run as an Apache Yarn application. The id of this application
# is stored on this file.
APPLICATION_ID="$INSTALLATION_PATH/flink/flink.pid"

# The full path of the lock file to use.
LOCKFILE="$INSTALLATION_PATH/flink/flink-lock"

# The command that will start Apache Flink.
START_COMMAND="$INSTALLATION_PATH/flink/bin/yarn-session.sh -n {{ number_of_taskmanagers }} -tm {{ ram_per_task_manager }}"

# The command that will stop Apache Flink. Note that, HADOOP_HOME home variable should be set outside from this script and
# before Flink's deployment.
STOP_COMMAND="$HADOOP_HOME/bin/yarn application --kill"

start(){
  # Assert that there is no other Apache Flink instance, created with this script, running.
  [ -f $LOCKFILE ] && return 0

  # Execute the command to start Apache Flink.
  sudo -E -u $SCRIPT_USER nohup $START_COMMAND > /dev/null &

  # Get the returned value and create a lock file to prevent multiple instantiations.
  RETVAL=$?
  [ $RETVAL -eq 0 ] && $(sudo -u $SCRIPT_USER touch $LOCKFILE)

  # Wait for a minute Apache Flink to start. The condition check whether an application under user "flink" has been
  # started on Apache Yarn and whether a minute has passed.
  i=0
  while [ "$(sudo -u $SCRIPT_USER $HADOOP_HOME/bin/yarn application --list | cut -f4 | grep "flink")" == "" ] && [ $i -lt 6 ]
  do
    sleep 10
    i=$((i+1))
  done

  # Save the application id of this Apache Flink application.
  $(sudo -u $SCRIPT_USER $HADOOP_HOME/bin/yarn application --list | cut -f1,4 | grep "flink" | cut -f1 > $APPLICATION_ID)
  chown $SCRIPT_USER $APPLICATION_ID
  chmod 644 $APPLICATION_ID

  return $RETVAL
}

stop(){
  # Assert that an Apache Flink instance, created with this script, is running.
  [ ! -f $LOCKFILE ] && return 0

  # Read the application id and execute the command to stop Apache Flink. The command will block
  # until the service has been stopped.
  id=$(sudo -u $SCRIPT_USER cat $APPLICATION_ID)
  sudo -E -u $SCRIPT_USER $STOP_COMMAND $id > /dev/null

  # Delete the files on Apache HDFS created when Apache Flink was started.
  # These files are created by Apache Yarn to distribute Flink accross all nodes.
  sudo -u $SCRIPT_USER $HADOOP_HOME/bin/hadoop fs -rm -r -skipTrash /user/flink/.flink/$id

  # Delete application id file.
  sudo -u $SCRIPT_USER rm $APPLICATION_ID

  # Get the returned value of the executed command and remove the lock file.
  RETVAL=$?
  [ $RETVAL -eq 0 ] && $(sudo -u $SCRIPT_USER rm -f $LOCKFILE)
  return $RETVAL
}

restart(){
  stop
  start
}

RETVAL=0

case "$1" in
  start)
    start
    ;;
  stop)
    stop
    ;;
  restart|reload|force-reload)
    restart
    ;;
  condrestart)
    [ -f $LOCKFILE ] && restart || :
    ;;
  status)
    # If the lock file exists, then Apache Flink is running.
    [ -f $LOCKFILE ] && echo "Apache Flink is running." || echo "Apache Flink is not running."
    RETVAL=$?
    ;;
  *)
    echo "Usage: $0 {start|stop|status|restart|reload|force-reload|condrestart}"
    RETVAL=1
esac

exit $RETVAL

